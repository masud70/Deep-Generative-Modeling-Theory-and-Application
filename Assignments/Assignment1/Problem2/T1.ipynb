{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c6cddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\UManitoba\\DGM\\Codes\\.venv\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "g:\\UManitoba\\DGM\\Codes\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea123dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, _), (x_test, _) = keras.datasets.mnist.load_data()\n",
    "mnist_digits = np.concatenate([x_train, x_test], axis=0)\n",
    "mnist_digits = np.expand_dims(mnist_digits, -1).astype(\"float32\") / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9609b7a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From g:\\UManitoba\\DGM\\Codes\\.venv\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 2\n",
    "\n",
    "encoder_inputs = keras.Input(shape=(28, 28, 1))\n",
    "x = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\n",
    "x = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2D(128, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(16, activation=\"relu\")(x)\n",
    "z = layers.Dense(latent_dim, name=\"z\")(x)\n",
    "encoder = keras.Model(encoder_inputs, z, name=\"encoder\")\n",
    "# encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93c7060",
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_inputs = keras.Input(shape=(latent_dim,))\n",
    "x = layers.Dense(7 * 7 * 128, activation=\"relu\")(latent_inputs)\n",
    "x = layers.Reshape((7, 7, 128))(x)\n",
    "x = layers.Conv2DTranspose(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\n",
    "x = layers.Conv2DTranspose(32, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\n",
    "decoder_outputs = layers.Conv2DTranspose(1, 3, activation=\"sigmoid\", padding=\"same\")(x)\n",
    "decoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\n",
    "# decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e2bcaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AE(keras.Model):\n",
    "    def __init__(self, encoder, decoder, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n",
    "        self.reconstruction_loss_tracker = keras.metrics.Mean(\n",
    "            name=\"reconstruction_loss\"\n",
    "        )\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.total_loss_tracker,\n",
    "            self.reconstruction_loss_tracker,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, data):\n",
    "        with tf.GradientTape() as tape:\n",
    "            z = self.encoder(data)\n",
    "            reconstruction = self.decoder(z)\n",
    "            reconstruction_loss = tf.reduce_mean(\n",
    "                tf.reduce_sum(\n",
    "                    keras.losses.binary_crossentropy(data, reconstruction),\n",
    "                    axis=(1, 2),\n",
    "                )\n",
    "            )\n",
    "            total_loss = reconstruction_loss\n",
    "        grads = tape.gradient(total_loss, self.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n",
    "        self.total_loss_tracker.update_state(total_loss)\n",
    "        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n",
    "        return {\n",
    "            \"loss\": self.total_loss_tracker.result(),\n",
    "            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n",
    "        }\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        z = self.encoder(inputs)\n",
    "        reconstruction = self.decoder(z)\n",
    "        return reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c34ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
      "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
     ]
    }
   ],
   "source": [
    "ae = AE(encoder, decoder)\n",
    "ae.load_weights(\"model/P1T1_AE_mnist.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa018a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_image(img, mask_size=12):\n",
    "    img_masked = img.copy()\n",
    "    \n",
    "    H, W, _ = img.shape\n",
    "    \n",
    "    # Random top-left corner\n",
    "    x = np.random.randint(0, H - mask_size)\n",
    "    y = np.random.randint(0, W - mask_size)\n",
    "    \n",
    "    img_masked[x:x+mask_size, y:y+mask_size, :] = 0.0\n",
    "    \n",
    "    return img_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b06c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 0s 373ms/step\n"
     ]
    }
   ],
   "source": [
    "num_samples = 10\n",
    "indices = np.random.choice(len(mnist_digits), num_samples, replace=False)\n",
    "\n",
    "originals = mnist_digits[indices]\n",
    "masked = np.array([mask_image(img, mask_size=10) for img in originals])\n",
    "\n",
    "reconstructed = ae.decoder.predict(ae.encoder.predict(masked))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3eacdffb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_samples' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fig, axes \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m3\u001b[39m, \u001b[43mnum_samples\u001b[49m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m15\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_samples):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;66;03m# Original\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     axes[\u001b[38;5;241m0\u001b[39m, i]\u001b[38;5;241m.\u001b[39mimshow(originals[i], cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_samples' is not defined"
     ]
    }
   ],
   "source": [
    "fig, axes = plt.subplots(3, num_samples, figsize=(15, 6))\n",
    "\n",
    "for i in range(num_samples):\n",
    "    # Original\n",
    "    axes[0, i].imshow(originals[i], cmap='gray')\n",
    "    axes[0, i].set_title(f\"Example: {i+1}\")\n",
    "    axes[0, i].axis(\"off\")\n",
    "\n",
    "    # Masked\n",
    "    axes[1, i].imshow(masked[i], cmap='gray')\n",
    "    axes[1, i].axis(\"off\")\n",
    "\n",
    "    # Reconstructed\n",
    "    axes[2, i].imshow(reconstructed[i], cmap='gray')\n",
    "    axes[2, i].axis(\"off\")\n",
    "\n",
    "fig.text(0.0, 0.8, \"Original\", va='center', rotation='vertical', fontsize=10)\n",
    "fig.text(0.0, 0.51, \"Masked\", va='center', rotation='vertical', fontsize=10)\n",
    "fig.text(0.0, 0.2, \"Reconstructed\", va='center', rotation='vertical', fontsize=10)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
